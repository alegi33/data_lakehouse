{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98269e49-960e-47b0-bd10-16058e7ea270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a9e4d3e-a5a3-4428-a330-b9398dc1b7bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+----+\n|_c0|       _c1|_c2| _c3|\n+---+----------+---+----+\n|  1|2019-05-01|9.0|1000|\n|  2|2019-06-01|9.0|1000|\n|  3|2019-07-01|9.0|1000|\n+---+----------+---+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ingest payments.csv\n",
    "payments_df = spark.read.format('csv') \\\n",
    "\t.option('inferSchema','false') \\\n",
    "\t.option('header','false') \\\n",
    "\t.option('sep',',') \\\n",
    "\t.load('/FileStore/alegiproject/payments.csv')\n",
    "\n",
    "payments_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2469f4c-03ad-4d5a-b0b2-4937e5c33d15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------------+\n|payment_id|      date|amount|account_number|\n+----------+----------+------+--------------+\n|         1|2019-05-01|   9.0|          1000|\n|         2|2019-06-01|   9.0|          1000|\n|         3|2019-07-01|   9.0|          1000|\n+----------+----------+------+--------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add header into payments_df\n",
    "spark = SparkSession.builder.appName(\"AddHeader\").getOrCreate()\n",
    "payments_headers = [\"payment_id\",\"date\",\"amount\",\"account_number\"]\n",
    "payments_df = payments_df.toDF(*payments_headers)\n",
    "payments_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f5cb2f-524d-4b7e-a67f-952edd54b8b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save payments_df as parquet in delta lake\n",
    "payments_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c298c16f-c4b5-43e0-99c5-0265f011eec6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+--------------------+----------+----------+----------+----+\n| _c0|     _c1|  _c2|                 _c3|       _c4|       _c5|       _c6| _c7|\n+----+--------+-----+--------------------+----------+----------+----------+----+\n|1000|   Diana|Clark| 1200 Alyssa Squares|1989-02-13|2019-04-23|      null|True|\n|1001|Jennifer|Smith|     397 Diana Ferry|1976-08-10|2019-11-01|2020-09-01|True|\n|1002|   Karen|Smith|644 Brittany Row ...|1998-08-10|2022-02-04|      null|True|\n+----+--------+-----+--------------------+----------+----------+----------+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ingest payments.csv\n",
    "riders_df = spark.read.format('csv') \\\n",
    "\t.option('inferSchema','false') \\\n",
    "\t.option('header','false') \\\n",
    "\t.option('sep',',') \\\n",
    "\t.load('/FileStore/alegiproject/riders.csv')\n",
    "\n",
    "riders_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f9ef75-b817-4a75-becd-789235ddfa8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|             address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|    1000|     Diana|    Clark| 1200 Alyssa Squares|1989-02-13|        2019-04-23|            null|     True|\n|    1001|  Jennifer|    Smith|     397 Diana Ferry|1976-08-10|        2019-11-01|      2020-09-01|     True|\n|    1002|     Karen|    Smith|644 Brittany Row ...|1998-08-10|        2022-02-04|            null|     True|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add header into riders_df\n",
    "spark = SparkSession.builder.appName(\"AddHeader\").getOrCreate()\n",
    "riders_headers = [\"rider_id\",\"first_name\",\"last_name\",\"address\",\"birthday\",\"account_start_date\",\"account_end_date\",\"is_member\"]\n",
    "riders_df = riders_df.toDF(*riders_headers)\n",
    "riders_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc65eac-db26-4f63-9e70-5c797f72ad16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save riders_df as parquet in delta lake\n",
    "riders_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e5c604-8cfe-4169-81c5-88f1bba5d9cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|         _c0|                 _c1|              _c2|               _c3|\n+------------+--------------------+-----------------+------------------+\n|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n|         637|Wood St & Chicago...|        41.895634|        -87.672069|\n+------------+--------------------+-----------------+------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ingest stations.csv\n",
    "stations_df = spark.read.format('csv') \\\n",
    "\t.option('inferSchema','false') \\\n",
    "\t.option('header','false') \\\n",
    "\t.option('sep',',') \\\n",
    "\t.load('/FileStore/alegiproject/stations.csv')\n",
    "\n",
    "stations_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a5dac32-d83d-44fb-8af0-6a0f6604c691",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|  station_id|        station_name|         latitude|         longitude|\n+------------+--------------------+-----------------+------------------+\n|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n|         637|Wood St & Chicago...|        41.895634|        -87.672069|\n+------------+--------------------+-----------------+------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add header into stations_df\n",
    "spark = SparkSession.builder.appName(\"AddHeader\").getOrCreate()\n",
    "stations_headers = [\"station_id\",\"station_name\",\"latitude\",\"longitude\"]\n",
    "stations_df = stations_df.toDF(*stations_headers)\n",
    "stations_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb4a6e2-bbec-4eed-b4c1-d503a0f46158",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save stations_df as parquet in delta late\n",
    "stations_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35b33d7-3cb0-4c84-b4a2-eb6a3cf1a486",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n|             _c0|          _c1|                _c2|                _c3|         _c4|         _c5|  _c6|\n+----------------+-------------+-------------------+-------------------+------------+------------+-----+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|         525|         660|71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|         525|       16806|47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|KA1503000012|TA1305000029|70870|\n+----------------+-------------+-------------------+-------------------+------------+------------+-----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ingest trips.csv\n",
    "trips_df = spark.read.format('csv') \\\n",
    "\t.option('inferSchema','false') \\\n",
    "\t.option('header','false') \\\n",
    "\t.option('sep',',') \\\n",
    "\t.load('/FileStore/alegiproject/trips.csv')\n",
    "\n",
    "trips_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1a79b6-e3a1-47e2-a9eb-d3d6e6baa484",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|rider_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|    KA1503000012|  TA1305000029|   70870|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add header into trips_df\n",
    "spark = SparkSession.builder.appName(\"AddHeader\").getOrCreate()\n",
    "trips_headers = [\"trip_id\",\"rideable_type\",\"started_at\",\"ended_at\",\"start_station_id\",\"end_station_id\",\"rider_id\"]\n",
    "trips_df = trips_df.toDF(*trips_headers)\n",
    "trips_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124b6bc6-64ac-469f-9b3a-3f3efb103aa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save trips_df as parquet in delta lake\n",
    "trips_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbbc7675-32b0-409e-926a-bbacdc127ace",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---+-------+---+---+---+---+---------+----+\n|     _c0|     _c1| _c2|_c3|    _c4|_c5|_c6|_c7|_c8|      _c9|_c10|\n+--------+--------+----+---+-------+---+---+---+---+---------+----+\n|19910101|1/1/1991|1991|  1|January|  1|  1|  1|  3|  Tuesday|   1|\n|19910102|1/2/1991|1991|  1|January|  1|  2|  2|  4|Wednesday|   1|\n|19910103|1/3/1991|1991|  1|January|  1|  3|  3|  5| Thursday|   1|\n+--------+--------+----+---+-------+---+---+---+---+---------+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ingest dates.csv\n",
    "dates_df = spark.read.format('csv') \\\n",
    "\t.option('inferSchema','false') \\\n",
    "\t.option('header','false') \\\n",
    "\t.option('sep',',') \\\n",
    "\t.load('/FileStore/alegiproject/dates.csv')\n",
    "    \n",
    "dates_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e39c16a-0db9-4b3e-a67c-e691f6b4eeb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\n| datekey|    date|year|month_num|month_name|week_num|day_num_of_year|day_num_of_month|day_num_of_week| day_name|quarter|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\n|19910101|1/1/1991|1991|        1|   January|       1|              1|               1|              3|  Tuesday|      1|\n|19910102|1/2/1991|1991|        1|   January|       1|              2|               2|              4|Wednesday|      1|\n|19910103|1/3/1991|1991|        1|   January|       1|              3|               3|              5| Thursday|      1|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add header into dates_df\n",
    "spark = SparkSession.builder.appName(\"AddHeader\").getOrCreate()\n",
    "dates_headers = [\"datekey\",\"date\",\"year\",\"month_num\",\"month_name\",\"week_num\",\"day_num_of_year\",\"day_num_of_month\",\"day_num_of_week\",\"day_name\",\"quarter\"]\n",
    "dates_df = dates_df.toDF(*dates_headers)\n",
    "dates_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bb56485-12af-4839-a990-822d3bd7813f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save dates_df as parquet in delta lake\n",
    "dates_df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c268025b-66a4-4989-9500-2ad4df1b3c2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# create payments table\n",
    "spark.sql(\"CREATE TABLE payments USING DELTA LOCATION '/delta/payments'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d5a2721-b79f-4233-834a-d2899d1b617b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# create riders table\n",
    "spark.sql(\"CREATE TABLE riders USING DELTA LOCATION '/delta/riders'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb87f13-0c73-4f23-9b48-d0ddffceb0ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# create stations table\n",
    "spark.sql(\"CREATE TABLE stations USING DELTA LOCATION '/delta/stations'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a963206-5755-45cd-a9b2-e3abf984b8a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[29]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# create trips table\n",
    "spark.sql(\"CREATE TABLE trips USING DELTA LOCATION '/delta/trips'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "421a4610-f9c8-4f6e-a141-51b2ca64e087",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# create dates table\n",
    "spark.sql(\"CREATE TABLE dates USING DELTA LOCATION '/delta/dates'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad456183-6303-44ff-a603-1f4c6c3dbe6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------------+\n|payment_id|      date|amount|account_number|\n+----------+----------+------+--------------+\n|         1|2019-05-01|   9.0|          1000|\n|         2|2019-06-01|   9.0|          1000|\n|         3|2019-07-01|   9.0|          1000|\n+----------+----------+------+--------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# creating fact_payment table\n",
    "payments_tbl = spark.table(\"default.payments\")\n",
    "payments_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ed8dc7-f5d3-4875-a649-47709fd7f9ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------------+--------+\n|payment_id|      date|amount|account_number|date_key|\n+----------+----------+------+--------------+--------+\n|         1|2019-05-01|   9.0|          1000|20190501|\n|         2|2019-06-01|   9.0|          1000|20190601|\n|         3|2019-07-01|   9.0|          1000|20190701|\n+----------+----------+------+--------------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# create date_key column\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "payments_tbl = payments_tbl.withColumn(\"date_key\", regexp_replace(\"date\", \"-\", \"\"))\n",
    "payments_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa022ae7-1721-4ffb-9e5f-ec488b83c73e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------------+--------+\n|payment_id|      date|amount|account_number|date_key|\n+----------+----------+------+--------------+--------+\n|         1|2019-05-01|   9.0|          1000|20190501|\n|         2|2019-06-01|   9.0|          1000|20190601|\n|         3|2019-07-01|   9.0|          1000|20190701|\n+----------+----------+------+--------------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# change data type to follow star schema\n",
    "payments_tbl = payments_tbl.selectExpr(\"cast(payment_id as int) payment_id\", \"cast(date as date) date\", \"cast(amount as float) amount\", \"cast(account_number as int) account_number\", \"cast(date_key as int) date_key\")\n",
    "payments_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70ef02a-4844-46f9-a87e-e90b74eeb68e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as delta table\n",
    "payments_tbl.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fact_payment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce72c0c-6f34-400c-a59f-cc981f34ba3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|             address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|    1000|     Diana|    Clark| 1200 Alyssa Squares|1989-02-13|        2019-04-23|            null|     True|\n|    1001|  Jennifer|    Smith|     397 Diana Ferry|1976-08-10|        2019-11-01|      2020-09-01|     True|\n|    1002|     Karen|    Smith|644 Brittany Row ...|1998-08-10|        2022-02-04|            null|     True|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# creating dim_rider table\n",
    "riders_tbl = spark.table(\"default.riders\")\n",
    "riders_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9711088-4e94-4502-a616-b798804cde33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+----------+---------+\n|rider_id|first_name|last_name|             address|  birthday|is_member|\n+--------+----------+---------+--------------------+----------+---------+\n|    1000|     Diana|    Clark| 1200 Alyssa Squares|1989-02-13|     true|\n|    1001|  Jennifer|    Smith|     397 Diana Ferry|1976-08-10|     true|\n|    1002|     Karen|    Smith|644 Brittany Row ...|1998-08-10|     true|\n+--------+----------+---------+--------------------+----------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# select columns as per star schema and change data type\n",
    "from pyspark.sql.functions import col\n",
    "riders_tbl = riders_tbl.select(\"rider_id\",\"first_name\",\"last_name\",\"address\",\"birthday\",\"is_member\") \\\n",
    "    .selectExpr(\"cast(rider_id as int) rider_id\", \"cast(first_name as string) first_name\", \"cast(last_name as string) last_name\", \"cast(address as string) address\", \"cast(birthday as date)\", \"cast(is_member as boolean) is_member\")\n",
    "riders_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44a016ea-8733-4fb7-867e-2fceed39432d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as delta table\n",
    "riders_tbl.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dim_rider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8058cdf-3438-4ef8-9b61-0b973d039115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|  station_id|        station_name|         latitude|         longitude|\n+------------+--------------------+-----------------+------------------+\n|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n|         637|Wood St & Chicago...|        41.895634|        -87.672069|\n+------------+--------------------+-----------------+------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# creating dim_station table\n",
    "stations_tbl = spark.table(\"default.stations\")\n",
    "stations_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a49d133a-4a63-4fbc-989e-29f9dbfc4fba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+----------+\n|  station_id|        station_name| latitude| longitude|\n+------------+--------------------+---------+----------+\n|         525|Glenwood Ave & To...|  42.0127| -87.66606|\n|KA1503000012|  Clark St & Lake St|41.885796|  -87.6311|\n|         637|Wood St & Chicago...|41.895634|-87.672066|\n+------------+--------------------+---------+----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# change data type as per star schema\n",
    "stations_tbl = stations_tbl.selectExpr(\"cast(station_id as string) station_id\", \"cast(station_name as string) station_name\", \"cast(latitude as float) latitude\",\"cast(longitude as float) longitude\")\n",
    "stations_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0544f2f5-2dd5-47bf-a02d-eef2809dcc54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as delta table\n",
    "stations_tbl.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dim_station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3da1998a-0e60-4941-bc3f-08bf400a1abf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\n| datekey|    date|year|month_num|month_name|week_num|day_num_of_year|day_num_of_month|day_num_of_week| day_name|quarter|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\n|19910101|1/1/1991|1991|        1|   January|       1|              1|               1|              3|  Tuesday|      1|\n|19910102|1/2/1991|1991|        1|   January|       1|              2|               2|              4|Wednesday|      1|\n|19910103|1/3/1991|1991|        1|   January|       1|              3|               3|              5| Thursday|      1|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# creating dim_date table\n",
    "dates_tbl = spark.table(\"default.dates\")\n",
    "dates_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ee41b47-6a93-4c36-b916-8f277e292cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n| datekey|    date|year|month_num|month_name|week_num|day_num_of_year|day_num_of_month|day_num_of_week| day_name|quarter|is_weekend|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n|19910101|1/1/1991|1991|        1|   January|       1|              1|               1|              3|  Tuesday|      1|         0|\n|19910102|1/2/1991|1991|        1|   January|       1|              2|               2|              4|Wednesday|      1|         0|\n|19910103|1/3/1991|1991|        1|   January|       1|              3|               3|              5| Thursday|      1|         0|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# add weekend flag column\n",
    "from pyspark.sql.functions import expr\n",
    "dates_tbl = dates_tbl.withColumn(\"is_weekend\", expr(\"CASE WHEN day_name in ('Saturday','Sunday') THEN 1 ELSE 0 END\"))\n",
    "dates_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e712afa-fedd-41b3-b4ed-7940ae9718ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n|date_key|    date|year|month_num|month_name|week_num|day_num_of_year|day_num_of_month|day_num_of_week| day_name|quarter|is_weekend|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n|19910101|1/1/1991|1991|        1|   January|       1|              1|               1|              3|  Tuesday|      1|         0|\n|19910102|1/2/1991|1991|        1|   January|       1|              2|               2|              4|Wednesday|      1|         0|\n|19910103|1/3/1991|1991|        1|   January|       1|              3|               3|              5| Thursday|      1|         0|\n+--------+--------+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# rename column\n",
    "dates_tbl = dates_tbl.withColumnRenamed(\"datekey\",\"date_key\")\n",
    "dates_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f2a8f00-f3c9-4d59-b10b-353e58886ac7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n|date_key|date|year|month_num|month_name|week_num|day_num_of_year|day_num_of_month|day_num_of_week| day_name|quarter|is_weekend|\n+--------+----+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\n|19910101|null|1991|        1|   January|       1|              1|               1|              3|  Tuesday|      1|     false|\n|19910102|null|1991|        1|   January|       1|              2|               2|              4|Wednesday|      1|     false|\n|19910103|null|1991|        1|   January|       1|              3|               3|              5| Thursday|      1|     false|\n+--------+----+----+---------+----------+--------+---------------+----------------+---------------+---------+-------+----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# change data type\n",
    "dates_tbl = dates_tbl.selectExpr(\"cast(date_key as int) date_key\", \"cast(date as date) date\", \"cast(year as int) year\", \"cast(month_num as int) month_num\",\"cast(month_name as string) month_name\",\"cast(week_num as int) week_num\",\"cast(day_num_of_year as int) day_num_of_year\",\"cast(day_num_of_month as int) day_num_of_month\",\"cast(day_num_of_week as int) day_num_of_week\", \"cast(day_name as string) day_name\",\"cast(quarter as int) quarter\",\"cast(is_weekend as boolean) is_weekend\")\n",
    "dates_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c6e3e5-a0fe-423a-939c-047b25861876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as delta table\n",
    "dates_tbl.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dim_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a8665b-5631-454e-ab50-bca92d4f961e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|rider_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|    KA1503000012|  TA1305000029|   70870|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# creating fact_trip table\n",
    "trips_tbl = spark.table(\"default.trips\")\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c404a7c-2315-4f67-b2c6-d5d90ef93ad0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|member_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|    71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|    47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|    KA1503000012|  TA1305000029|    70870|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# rename rider_id to member_id\n",
    "trips_tbl = trips_tbl.withColumnRenamed(\"rider_id\",\"member_id\")\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ee93824-ee43-40c5-b8cc-848c71a0c34b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|member_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|    71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|    47854|\n|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|    KA1503000012|  TA1305000029|    70870|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# change data type to timestamp for time calculation\n",
    "from pyspark.sql.functions import *\n",
    "trips_tbl = trips_tbl.withColumn(\"started_at\", to_timestamp(\"started_at\", 'yyyy-MM-dd HH:mm:ss'))\n",
    "trips_tbl = trips_tbl.withColumn(\"ended_at\", to_timestamp(\"ended_at\", 'yyyy-MM-dd HH:mm:ss'))\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abdf7004-2317-4899-a128-a16ade0d79ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|member_id|start_date|date_key|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+\n|222BB8E5059252D7| classic_bike|2021-06-13 09:48:47|2021-06-13 10:07:23|    KA1503000064|         13021|    34062|2021-06-13|20210613|\n|1826E16CB5486018| classic_bike|2021-06-21 22:59:13|2021-06-21 23:04:29|    TA1306000010|         13021|     5342|2021-06-21|20210621|\n|3D9B6A0A5330B04D| classic_bike|2021-06-18 16:06:42|2021-06-18 16:12:02|    TA1305000030|         13021|     3714|2021-06-18|20210618|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# create date_key column\n",
    "trips_tbl = trips_tbl.withColumn('start_date', col('started_at').cast('date'))\n",
    "trips_tbl = trips_tbl.withColumn(\"date_key\", regexp_replace(\"start_date\", \"-\", \"\"))\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97dd641a-3e67-406e-a055-6c5b28c05e31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|member_id|start_date|date_key|hour|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+\n|222BB8E5059252D7| classic_bike|2021-06-13 09:48:47|2021-06-13 10:07:23|    KA1503000064|         13021|    34062|2021-06-13|20210613|   9|\n|1826E16CB5486018| classic_bike|2021-06-21 22:59:13|2021-06-21 23:04:29|    TA1306000010|         13021|     5342|2021-06-21|20210621|  22|\n|3D9B6A0A5330B04D| classic_bike|2021-06-18 16:06:42|2021-06-18 16:12:02|    TA1305000030|         13021|     3714|2021-06-18|20210618|  16|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# extract hour into a separate column\n",
    "trips_tbl = trips_tbl.withColumn('hour', hour(trips_tbl.started_at))\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d9a96bc-d210-4cb4-a77b-191e78585658",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+---------------+\n|         trip_id|rideable_type|         started_at|           ended_at|start_station_id|end_station_id|member_id|start_date|date_key|hour|trip_length_min|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+---------------+\n|222BB8E5059252D7| classic_bike|2021-06-13 09:48:47|2021-06-13 10:07:23|    KA1503000064|         13021|    34062|2021-06-13|20210613|   9|             18|\n|1826E16CB5486018| classic_bike|2021-06-21 22:59:13|2021-06-21 23:04:29|    TA1306000010|         13021|     5342|2021-06-21|20210621|  22|              5|\n|3D9B6A0A5330B04D| classic_bike|2021-06-18 16:06:42|2021-06-18 16:12:02|    TA1305000030|         13021|     3714|2021-06-18|20210618|  16|              5|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+---------+----------+--------+----+---------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# calculate trip duration\n",
    "trips_tbl = trips_tbl.withColumn(\"trip_length_min\", expr(\"datediff(minute,started_at,ended_at)\"))\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7a2d18f-a393-405e-aed7-0118c19c55a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\n|         trip_id|rideable_type|member_id|         started_at|           ended_at|start_station_id|end_station_id|date_key|hour|trip_length_min|age_at_trip|\n+----------------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\n|222BB8E5059252D7| classic_bike|    34062|2021-06-13 09:48:47|2021-06-13 10:07:23|    KA1503000064|         13021|20210613|   9|             18|         30|\n|1826E16CB5486018| classic_bike|     5342|2021-06-21 22:59:13|2021-06-21 23:04:29|    TA1306000010|         13021|20210621|  22|              5|         26|\n|3D9B6A0A5330B04D| classic_bike|     3714|2021-06-18 16:06:42|2021-06-18 16:12:02|    TA1305000030|         13021|20210618|  16|              5|         26|\n+----------------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# calculate age_at_trip\n",
    "trips_tbl = trips_tbl.join(riders_tbl, trips_tbl.member_id == riders_tbl.rider_id, \"left\") \\\n",
    "    .withColumn(\"age_at_trip\", expr(\"datediff(year,birthday,started_at) - case when dateadd(year,datediff(year,birthday,started_at),birthday) > started_at then 1 else 0 end\")) \\\n",
    "    .select(\"trip_id\",\"rideable_type\",\"member_id\",\"started_at\",\"ended_at\",\"start_station_id\",\"end_station_id\",\"date_key\",\"hour\",\"trip_length_min\",\"age_at_trip\")\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b54316-8c64-4792-a0ed-09359d9c8718",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\n|trip_id|rideable_type|member_id|         started_at|           ended_at|start_station_id|end_station_id|date_key|hour|trip_length_min|age_at_trip|\n+-------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\n|   null| classic_bike|    34062|2021-06-13 09:48:47|2021-06-13 10:07:23|    KA1503000064|         13021|20210613|   9|             18|         30|\n|   null| classic_bike|     5342|2021-06-21 22:59:13|2021-06-21 23:04:29|    TA1306000010|         13021|20210621|  22|              5|         26|\n|   null| classic_bike|     3714|2021-06-18 16:06:42|2021-06-18 16:12:02|    TA1305000030|         13021|20210618|  16|              5|         26|\n+-------+-------------+---------+-------------------+-------------------+----------------+--------------+--------+----+---------------+-----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "# change data type\n",
    "trips_tbl = trips_tbl.selectExpr(\"cast(trip_id as int) trip_id\",\"cast(rideable_type as string) rideable_type\",\"cast(member_id as int) member_id\",\"started_at\",\"ended_at\",\"start_station_id\",\"end_station_id\",\"cast(date_key as int) date_key\",\"cast(hour as int) hour\",\"cast(trip_length_min as int) trip_length_min\",\"cast(age_at_trip as int) age_at_trip\")\n",
    "trips_tbl.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fadf2f-601f-47bf-a304-c01a27ebcfe5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# save as delta table\n",
    "trips_tbl.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fact_trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a594147-15f7-4f2b-a91a-7b8a26a16b5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "datalake_project",
   "notebookOrigID": 4330274253083009,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
